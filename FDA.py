# -*- coding: utf-8 -*-
"""FDA - Final project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xSY4g9em-VAFzHY5QtqDQmbATYaKPwMx
"""

from google.colab import drive
drive.mount('/contentdrive/')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import datetime as dt
from scipy.stats import kurtosis
from scipy.stats import skew
from scipy.stats import boxcox

# Commented out IPython magic to ensure Python compatibility.
import warnings
warnings.filterwarnings('ignore')

# %matplotlib inline
# Import libraries

import os
for dirname, _, filenames in os.walk('/contentdrive/Shareddrives/FDA-Ca1 T4 /Final project/Final/data final.xlsx'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import io
avtworks = pd.read_excel('/contentdrive/Shareddrives/FDA-Ca1 T4 /Final project/Final/data final.xlsx')

"""# **EDA and DATA PREPROCESSING**"""

avtworks.sample

avtworks.head()

avtworks.shape

avtworks.describe()

avtworks.info()

avtworks.dtypes

avtworks['OrderDateKey'].unique()

avtworks.isnull().sum().sort_values(ascending=False)

avtworks.hist(figsize =(20,10))
plt.show();

corravtworks = avtworks.corr()
sns.heatmap(corravtworks, 
        xticklabels=corravtworks,
        yticklabels=corravtworks.columns, cmap='coolwarm_r')

sns.scatterplot(data=avtworks, x='OrderDateKey', y='Sales Amount')
plt.xlabel('OrderDateKey')
plt.ylabel('Sales Amount');

avtworks.plot(kind = 'box', subplots = True, figsize = (20,10))

fig = plt.figure(figsize =(10, 7))

avtworks=avtworks.drop_duplicates()
avtworks.shape

avtworks.Date.max()

avtworks['Sales Amount']

pin_date = dt.datetime(2020, 6,20)

rfm = avtworks.groupby('CustomerKey').agg({'Date': lambda Date: (pin_date - Date.max()).days,
                                     'OrderDateKey': lambda OrderDateKey: OrderDateKey.nunique(),
                                     'Sales Amount': lambda Sales_Amount: Sales_Amount.sum()})

rfm.head()

"""# **RFM VALUES**"""

rfm.rename(columns={'Date': 'recency', 'OrderDateKey': 'frequency', 'Sales Amount': 'monetary'}, inplace=True)
rfm.head()

rfm.hist(figsize =(20,10))
plt.show();

rfm.plot(kind = 'box', subplots = True, figsize = (20,10))

from scipy.stats import kurtosis

print(kurtosis(rfm, axis=0, bias=True))

from scipy.stats import skew
print(skew(rfm, axis=0, bias=True))

plt.boxplot(rfm.recency)
Q1 = rfm.recency.quantile(0.25)
Q3 = rfm.recency.quantile(0.75)
IQR = Q3 - Q1
rfm = rfm[(rfm.recency >= Q1 - 1.5*IQR) & (rfm.recency <= Q3 + 1.5*IQR)]

plt.boxplot(rfm.frequency)
Q1 = rfm.frequency.quantile(0.25)
Q3 = rfm.frequency.quantile(0.75)
IQR = Q3 - Q1
rfm = rfm[(rfm.frequency >= Q1 - 1.5*IQR) & (rfm.frequency <= Q3 + 1.5*IQR)]

plt.boxplot(rfm.monetary)
Q1 = rfm.monetary.quantile(0.25)
Q3 = rfm.monetary.quantile(0.75)
IQR = Q3 - Q1
rfm = rfm[(rfm.monetary >= (Q1 - 1.5*IQR)) & (rfm.monetary <= (Q3 + 1.5*IQR))]

from scipy.stats import kurtosis
from scipy.stats import skew

print(kurtosis(rfm, axis=0, bias=True))
print(skew(rfm, axis=0, bias=True))

corrrfm = rfm.corr()
sns.heatmap(corrrfm, 
        xticklabels=corrrfm,
        yticklabels=corrrfm.columns, cmap='coolwarm_r')

rfm["recency_score"] = pd.qcut(rfm['recency'], 5, labels=[5, 4, 3, 2, 1])


rfm["frequency_score"] = pd.qcut(rfm['frequency'].rank(method="first"), 5, labels=[1, 2, 3, 4, 5])

rfm["monetary_score"] = pd.qcut(rfm['monetary'], 5, labels=[1, 2, 3, 4, 5])

rfm['score']=rfm['recency_score'].astype(int)+rfm['frequency_score'].astype(int)+rfm['monetary_score'].astype(int)

rfm.head()

rfm[rfm['score']== 15].sort_values('monetary', ascending=False).head()

rfm[rfm['score']==15].count()

def rfm_level(score):
    if  ((score >= 3) and (score < 7)):
        return 'Inactive'
    elif ((score >= 7) and (score < 11)):
        return 'Average'
    elif ((score >= 11) and (score <15)):
        return 'Good'
    else:
        return 'Active'

rfm['level'] = rfm['score'].apply(lambda score : rfm_level(score))
rfm.head()

plt.figure(figsize=(10,5))
sns.set_context("poster", font_scale=0.7)
sns.set_palette('twilight')
sns.countplot(rfm['level'])

rfm.groupby('level').agg({
    'recency' : ['mean', 'min','max','count'],
    'frequency' : ['mean', 'min','max','count'],
    'monetary' : ['mean','min','max','count']
})

cross_table1 = pd.crosstab(index=rfm['monetary_score'], columns=rfm['frequency_score'])
cross_table2 = pd.crosstab(index=rfm['monetary_score'], columns=rfm['recency_score'])
cross_table3 = pd.crosstab(index=rfm['frequency_score'], columns=rfm['recency_score'])
plt.figure(figsize=(20,30))
plt.subplot(311)
ax1 = sns.heatmap(cross_table1, cmap='viridis', annot=True, fmt=".0f")
ax1.invert_yaxis()
ax1.set_ylabel('Monetary')
ax1.set_xlabel('Frequency')
ax1.set_title('Monetary vs Frequency')
plt.subplot(312)
ax2 = sns.heatmap(cross_table2, cmap='viridis', annot=True, fmt=".0f")
ax2.invert_yaxis()
ax2.set_ylabel('Monetary')
ax2.set_xlabel('Recency')
ax2.set_title('Monetary vs Recency')
plt.subplot(313)
ax3 = sns.heatmap(cross_table3, cmap='viridis', annot=True, fmt=".0f")
ax3.invert_yaxis()
ax3.set_ylabel('Frequency')
ax3.set_xlabel('Recency')
ax3.set_title('Recency vs Frequency')
plt.show()

active = rfm[rfm['level'] == 'Active']
average = rfm[rfm['level'] == 'Average']
good = rfm[rfm['level'] == 'Good']
inactive = rfm[rfm['level'] == 'Inactive']

active_df = pd.DataFrame()
active_df["customer_id"] = rfm[rfm["level"] == "Active"].index

active_df.to_excel("active_customers.xlsx", sheet_name='Active Customers Index')

average_df = pd.DataFrame()
average_df["customer_id"] = rfm[rfm["level"] == "Average"].index

average_df.to_excel("average_customers.xlsx", sheet_name='Average Customers Index')

good_df = pd.DataFrame()
good_df["customer_id"] = rfm[rfm["level"] == "Good"].index

good_df.to_excel("good_customers.xlsx", sheet_name='Good Customers Index')

inactive_df = pd.DataFrame()
inactive_df["customer_id"] = rfm[rfm["level"] == "Inactive"].index

inactive_df.to_excel("inactive_customers.xlsx", sheet_name='Inactive Customers Index')

rfm.describe()

"""# **KMEANS ANALYSIS**"""

from yellowbrick.cluster import KElbowVisualizer
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

rfm1=rfm[['recency','frequency','monetary']]
scaler = StandardScaler()
x_scaled=scaler.fit(rfm1)
x_scaled = scaler.fit_transform(rfm1)
x_scaled

model = KMeans()
visualizer = KElbowVisualizer(model, k=(1,12))
visualizer.fit(x_scaled)  
visualizer.show()

kmeans_scaled = KMeans(3)
kmeans_scaled.fit(x_scaled)
identified_clusters = kmeans_scaled.fit_predict(rfm1)
clusters_scaled = rfm1.copy()
clusters_scaled['cluster_pred']=kmeans_scaled.fit_predict(x_scaled)
print(identified_clusters)
sns.set(style="darkgrid")
print(" Our cluster centers are as follows")
print(kmeans_scaled.cluster_centers_)
f, ax = plt.subplots(figsize=(25, 5))
ax = sns.countplot(x="cluster_pred", data=clusters_scaled)
clusters_scaled.groupby(['cluster_pred']).count()

fig = plt.figure()
ax = plt.axes(projection='3d')
xline=clusters_scaled['recency']
yline=clusters_scaled['frequency']
zline=clusters_scaled['monetary']

ax.scatter3D(xline, zline,yline,c=clusters_scaled['cluster_pred'])
ax.view_init(30, 60)

from sklearn.metrics import silhouette_samples, silhouette_score
sil_score = silhouette_score(x_scaled, kmeans_scaled.labels_, metric='euclidean')
print('Silhouette Score: %.3f' % sil_score)

from yellowbrick.cluster import SilhouetteVisualizer
model = KMeans(3)
visualizer = SilhouetteVisualizer(model)
visualizer.fit(x_scaled)   
visualizer.poof()

rfm1['cluster']= clusters_scaled['cluster_pred']
rfm1['level']=rfm['level']

rfm1.groupby('cluster').agg({
    'recency' : ['mean','min','max'],
    'frequency' : ['mean','min','max'],
    'monetary' : ['mean','min','max','count']
})

rfm1.head()

rfm1.groupby(['cluster']).size()

rfm_scaled=pd.DataFrame()
rfm_scaled=rfm1.copy()
scaler=StandardScaler()
rfm_scaled[['recency', 'frequency','monetary']] = scaler.fit_transform(rfm_scaled[['recency', 'frequency','monetary']])
rfm_scaled['cust_id']=rfm1.index

rfm_scaled.head()

rfm_melted = pd.melt(frame= rfm_scaled, id_vars= ['cust_id', 'cluster','level'], var_name = 'metrics', value_name = 'value')
rfm_melted.head()

sns.lineplot(x = 'metrics', y = 'value', hue = 'level', data = rfm_melted)
plt.title('Snake Plot of RFM')
plt.legend(loc = 'upper right')

sns.lineplot(x = 'metrics', y = 'value', hue = 'cluster', data = rfm_melted)
plt.title('Snake Plot of Clusters')
plt.legend(loc = 'upper right')

"""# **PREDICTION CLV**"""

!pip install lifetimes

import lifetimes
from lifetimes import BetaGeoFitter # BG/NBD
from lifetimes import GammaGammaFitter # Gamma-Gamma Model
from lifetimes.plotting import plot_frequency_recency_matrix
pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)

clv = lifetimes.utils.summary_data_from_transaction_data(avtworks,'CustomerKey','Date','Sales Amount',observation_period_end='2020-06-15')

clv = clv[clv['frequency']>1] # we want only customers shopped more than 2 times

bgf = BetaGeoFitter(penalizer_coef=0.001)
bgf.fit(clv['frequency'], clv['recency'], clv['T'])

t = 180 # 30 day period
clv['expected_purc_6_months'] = bgf.conditional_expected_number_of_purchases_up_to_time(t, clv['frequency'], clv['recency'], clv['T'])
clv.sort_values(by='expected_purc_6_months',ascending=False).head(5)

clv[['frequency','monetary_value']].corr()

# Creating Gamma-Gamma Model
ggf = GammaGammaFitter(penalizer_coef=0.01) # model object
ggf.fit(clv['frequency'], clv['monetary_value']) # model fitting

clv['6_months_clv']=ggf.customer_lifetime_value(bgf,
                                   clv["frequency"],
                                   clv["recency"],
                                   clv["T"],
                                   clv["monetary_value"],
                                   time=6,
                                   freq='D',
                                   discount_rate=0.01)
clv.sort_values('6_months_clv',ascending=False).head()

ggf.summary

ggf.conditional_expected_average_profit(clv['frequency'], clv['monetary_value']).sort_values(ascending=False).head(10)

clv['expected_average_profit'] = ggf.conditional_expected_average_profit(clv['frequency'], clv['monetary_value'])

cltv = ggf.customer_lifetime_value(bgf, clv['frequency'], clv['recency'], clv['T'], clv['monetary_value'], time=6, freq='W')

cltv = cltv.reset_index()

cltv_final = clv.merge(cltv, on='CustomerKey', how='left')

cltv_final.sort_values(by='clv', ascending=False).head()

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler(feature_range=(0, 1))

cltv_final.head()

scaler.fit(cltv_final[['clv']])

cltv_final['scaled_cltv'] = scaler.transform(cltv_final[['clv']])

cltv_final.sort_values(by='scaled_cltv', ascending=False).head()

cltv_final.sort_values(by='scaled_cltv', ascending=False).tail()

cltv_final["segment"] = pd.qcut(cltv_final["scaled_cltv"], 4, labels= ['Active', 'Good', 'Average', 'Inactive'])
cltv_final.head()

cltv_final.head()

"""# **COHORT**"""

avtworks['Date'] = pd.to_datetime(avtworks['Date'], format='%m/%d/%Y %H:%M')

avtworks['order_month'] = avtworks['Date'].dt.to_period('M')

avtworks['cohort'] = avtworks.groupby('CustomerKey')['Date'].transform('min').dt.to_period('M')

avtworks_cohort = avtworks.groupby(['cohort', 'order_month']).agg(n_customers=('CustomerKey', 'nunique')).reset_index(drop=False)

from operator import attrgetter

avtworks_cohort['period_number'] = (avtworks_cohort.order_month - avtworks_cohort.cohort).apply(attrgetter('n'))

avtworks_cohort.head()

cohort_pivot = avtworks_cohort.pivot_table(index='cohort', columns='period_number', values='n_customers')

cohort_pivot

cohort_size = cohort_pivot.iloc[:, 0]
retention = cohort_pivot.divide(cohort_size,axis=0) #axis=0 to ensure the divide along the row axis

retention_matrix = cohort_pivot.divide(cohort_size, axis=0)

import matplotlib.colors as mcolors

#Build the heatmap or pictorial representation of above table

plt.figure(figsize=(25, 10))
plt.title('Retention Rates(in %) over one year period', size=12)
sns.heatmap(data=retention, annot = True, fmt = '.0%', cmap="summer_r")
plt.show()